## 提交的内容包括
* 实验报告.pdf  
是我们这次实验的实验报告。  
### 第一次大作业部分
* train_0.5B.ipynb   
为对Qwen-2.5-0.5B模型进行全量微调时使用的代码文件。
* 测评对比_0.5B.xlsx  
保存了Qwen-2.5-0.5B模型微调前后的测评结果对比。
* loss_0.5.xlsx   
保存了训练Qwen-2.5-0.5B模型时的loss的表格。
* https://www.kaggle.com/models/seathestars/sft_model_final  
我们小组的实验是在kaggle平台上进行的，最后将训练好的模型公开在了kaggle平台上，这个是模型的链接。
* https://jbox.sjtu.edu.cn/l/a13pt0
模型也上传到了交大云盘，这是云盘的链接。  
### 第二次大作业部分  
* train_1.5B.ipynb  
包含了对于bonus1的实现，即在Qwen-2.5-1.5B的基础上实现了PEFT微调，并以此作为聊天机器人的推理源。
* loss_1.5B.xlsx   
保存了训练Qwen-2.5-1.5B模型时的loss的表格。
* chatbot.ipynb  
包含了聊天机器人的基础部分以及对于bonus2和bonus3的实现，其中有详细说明。运行时，由于使用PEFT方法，需要同时导入原模型和微调后的PEFT模型。
* https://www.kaggle.com/models/seathestars/sft_model_1.5b
我们小组的实验是在kaggle平台上进行的，最后将训练好的模型公开在了kaggle平台上，这个是bounus1中微调后模型的链接。
* https://jbox.sjtu.edu.cn/l/o1sk8a
模型也上传到了交大云盘，这是云盘的链接。
